---
title: "Supplementary Material: Data Analysis"
author: "Matthew Lincoln"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Supplementary Material: Data Analysis}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r libraries, echo=FALSE, warnings = FALSE, message = FALSE, tidy = TRUE}
knitr::opts_chunk$set(warnings = FALSE, message = FALSE, fig.width = 7, fig.height = 5)
library(londonauctions)
library(tidyr)
library(dplyr)
library(ggplot2)
library(broom)
```

## Getty Sales Catalogs: What are the known unknowns?

```{r getty_distribution}
getty_distribution <- ggplot(getty_catalogs, aes(x = year, fill = is_input)) +
    geom_histogram(binwidth = 1) +
    scale_fill_brewer(type = "qual", palette = 6) +
    theme_bw() +
    annotate("rect", xmin = 1780, xmax = 1835, ymin = -Inf, ymax = Inf, alpha = 0.2) +
    annotate("text", x = 1800, y = 175, label = "1780-1835") +
    labs(x = NULL, y = "number of catalogs", fill = "contents indexed") +
    theme(legend.justification = c(0, 1), legend.position = c(0, 1))

dualplot(getty_distribution, "getty_distribution")
```

## Filters

Because the `price_factor` variable is dependent on all the other prices in the
database, we must make filtering decisions about including problematic records
before binning sales in to price quintiles. Do we want to include or exclude
problematic prices? What about certain transaction types? We can do that before
setting up the pricing categories.

```{r pre_factor_filter}

# Filter out sales whose prices are uncertain or which are doubled, while NOT 
# YET discarding those that had no price to begin with; these can be handled in
# later analysis.
sales <- sales %>% filter(amt_is_uncertain == FALSE & has_double_price == FALSE & transaction_type %in% c("sold", "bought in", "sold or bought in"))
```

## Price factor

Due to inflation and deflation, it is difficult to compare absolute prices
across the period of study. A simple solution to this problem is to categorize
artworks into groups of most expensive and least expensive within their own
years. The following function will group artowrks by year and split them into 5
buckets within their year, based on their price relative to other

```{r price_factor}
sales <- sales %>% 
  group_by(year) %>% 
  mutate(price_factor = ntile(transaction_amt, n = 5)) %>% 
  ungroup()
```

We may wish to break down the analysis of seasonal effect exhibited by specific
subsets of these data _after_ calculating the price factor. A prime candidate
for this is comparing auction houses, as they would still set their schedule
relative to each other in part based on these overall price factors.

```{r post_factor_filter}
sales <- sales %>% filter()
```

Code for generating Figure 1.

```{r per_year}
per_year <- ggplot(sales, aes(x = year)) +
  geom_histogram(binwidth = 1) +
  theme_bw() +
  theme(legend.position = "bottom") +
  labs(x = "Year", y = "Painting lots auctioned per year", fill = "has transaction price?")

dualplot(per_year, "per_year")
```

Code for generating Figure 2.

```{r per_month}
month_names <- c("January", "February", "March", "April", "May", "June", "July", "August", "September", "October", "November", "December")
per_month <- ggplot(sales %>% mutate(month = factor(month, labels = month_names)), aes(x = month)) +
  theme_bw() +
  geom_histogram() +
  theme(legend.position = "bottom") +
  labs(x = "Year", y = "Paintings auctioned per month", fill = "has transaction price?")

dualplot(per_month, "per_month")
```

We are interested in measuring how temporally-concentrated sales were in a given
year. Simply plotting out the number of sales on each day for a number of years
within our period of study suggests that auctioneers in later years increasingly
concentrated their sales within a shorter period.

```{r example_years}
sales %>% 
  filter(year %in% seq(1800, 1830, 10), price_factor == 5) %>% 
  count(year, yday) %>% 
  ggplot(aes(x = yday, y = n)) +
  geom_bar(stat = "identity") +
  facet_wrap(~ year, ncol = 1) +
  theme_bw() +
  labs(x = "Day of the year", y = "Number of sales")
```

To focus our analysis on the spread of the most successful sales for each year, 
we look for the top $n$ sale days for each year and calculate their _coefficient
of variation_.[^cv] Here is the same visualization of sale days, with the seven
top sales days for each year marked in red:

```{r example_top, echo=FALSE}
top_examples <- sales %>% 
  filter(year %in% seq(1800, 1830, 10), price_factor == 5) %>% 
  count(year, yday) %>% 
  mutate(
    # In the case that multiple days tie for the same number of sales, all will
    # be included in the calculation
    rank = min_rank(desc(n)),
    is_top = rank <= 7)
  
vis_top_example <- ggplot(top_examples, aes(x = yday, y = n, fill = is_top)) +
  geom_bar(stat = "identity") +
  scale_fill_manual(values = c("black", "red")) +
  facet_wrap(~ year, ncol = 1) +
  theme_bw() +
  theme(legend.position = "none") +
  labs(x = "Day of the year (with top seven days highlighted)", y = "Number of sales")

dualplot(vis_top_example, "vis_top_example", h = 7)
```

[^cv]: The coefficient of variation for a given set of numbers is the ratio of
the set's standard deviation to its mean. It shows the extent of variability in
the set relative to the mean value

From these example years, we see that the top-most days become increasingly
concentratee cgetween 1790 and 1830. The coefficient of variation (the standard
deviation of each day by the mean of all days) confirms this visual impression.
Years with more concentrated top sales days have a lower coefficient of
variation; their top sales days are simply closer to eachother in the calendar
year.

```{r, results='asis'}
cv_examples <- top_examples %>% 
  filter(is_top == TRUE) %>% 
  group_by(year) %>% 
  summarize(cv = sd(yday)/mean(yday))

knitr::kable(cv_examples, digits = 3)
```

We want to measure if the CV of yearly top sales days is significantly changing.
We also want to nuance this measurement with two additional facets: the price
factor of teh artwork (did it fall into the most expensive or least expensive of
artworks sold that year?) and three different ways of measuring the auction
performance of a given day: the number of lots sold, the sum of all recorded
transaction amounts per day, and the average lot price for that day.

First, we'll calculate the number of sales, total amount, and average amount for
every day of every year, grouping sales by their price factor:

```{r top_n}
# Calculate count, total, and average for every day of every year, grouped by
# price_factor
peaks <- sales %>%
  # Only consider records that have price information
  filter(!(is.na(price_factor))) %>%
  group_by(year, yday, price_factor) %>%
  summarize(
    daily_count = n(),
    daily_sum = sum(transaction_amt),
    daily_avg = daily_sum/daily_count
  )
```

Next, we will filter these results to include only the top 7 days of each year,
again grouped by price factor:

```{r}
# What number of top days will be considered in the calculation of seasonal
# spread?
n_days <- 7

# Find the top-N days in terms of daily_count, daily_sum, and daily_avg
peak_n <- peaks %>%
  group_by(year, price_factor) %>%
  top_n(n_days, daily_count) %>%
  select(year, price_factor, count_day = yday) %>% 
  ungroup()

peak_sum <- peaks %>%
  group_by(year, price_factor) %>%
  top_n(n_days, daily_sum) %>% 
  select(year, price_factor, sum_day = yday) %>% 
  ungroup()

peak_avg <- peaks %>%
  group_by(year, price_factor) %>%
  top_n(n_days, daily_avg) %>% 
  select(year, price_factor, avg_day = yday) %>% 
  ungroup()
```

Next, we will calculate the CV of these top days for each year and price factor.
Finally, we will run a linear regression model on these results. This is a
statistical tool for measuirng the correlation between variables in a dataset.
In this case, we wish to measure the correlation between the year (1780-1840)
and the coefficient of variation of top sales days. The linear regression gives
us a firm statistical footing to claim whether or not _the data we have_ support
the hypothesis that auctioneers increasingly scheduled top sales days close to
eachother in the calendar year.

```{r changing_cv}
# Calculate the coefficient of variation of the top-N days for each year and price
# factor - i.e. how spread apart through the year are they? Combine into one
# table for easy plotting and analysis
all_peaks <- peak_n %>% group_by(year, price_factor) %>% summarize(count_cv = sd(count_day)/mean(count_day)) %>%
  left_join(peak_sum %>% group_by(year, price_factor) %>% summarize(sum_cv = sd(sum_day)/mean(sum_day)), by = c("year", "price_factor")) %>%
  left_join(peak_avg %>% group_by(year, price_factor) %>% summarize(avg_cv = sd(avg_day)/mean(avg_day)), by = c("year", "price_factor")) %>%
  gather(type, cv, count_cv, sum_cv, avg_cv)

# Run linear regressions to find corellation between the year and the spread of
# top auction days
models <- all_peaks %>%
  group_by(price_factor, type) %>%
  do(lms = lm(year ~ cv, data = .)) %>%
  tidy(lms) %>%
  filter(term == "cv") %>% 
  mutate(sig = p.value < 0.05) %>% 
  ungroup()
```

The following facetted scatterplot presents the variation of top days, overlaid
with the results of our linear regression models. The years of the study period
(1780-1840) are along the x-axis of the plot, while the y-axis is the
coefficient of variation for sale days in that year. The dots represent the
actual measured points from the dataset, while the straight lines illustrate the
results of the linear regression model, providing a "line of best fit" for our
data that helps to visualize the strength of the relationship between the year
and the spread of top sales days in that year.

Because we also want to measure the effect of different measurement methods
**and** the relative price of the artworks being sold, we grouped our
cacluations by price factor and measurement method. In this figure, the groups
are vizualized with a faceted grid: each column represents the different price
factors of artworks, while each row represents a different measurement method.

```{r, fig.height=7}
# Join the significance calculations back onto the top-N-days data, so that we 
# can use ggplot to color each facet based on the value. Plot the change in 
# distribution of these top days between 1780-1840, coloring the plots based on
# the magnitude of the predicted change.
cv_results <- all_peaks %>%
  inner_join(models, by = c("price_factor", "type")) %>%
  mutate(
    type = factor(
      type,
      levels = c("avg_cv", "count_cv", "sum_cv"),
      labels = c( "Highest average price", "Highest number of sales", "Higest total revenue"))) %>%
  ggplot(aes(x = year, y = cv, color = estimate)) +
  geom_point(size = 3, alpha = 0.5) +
  geom_smooth(method = "lm") +
  facet_grid(type ~ price_factor) +
  theme_bw() +
  scale_color_gradient(low = "red", high = "black") +
  theme(
    legend.position = "none",
    axis.text.x = element_text(angle = 45, hjust = 1)
  ) +
  labs(
    x = "Year",
    y = paste0("Coefficient of variation of the top ", n_days, " days per year"),
    color = "Decrease in the CV of top sales days per year"
  )

dualplot(cv_results, "cv_results", h = 9, w = 9)
```

A benefit of this facetting is the ability to quickly discern that, in this
case, sales in the highest price bracket show a strong trend towards clustering,
regardless of measurement method. Similarly, we find that the spread of top days for lower 80% of sales (those in price factors 1 through 4) show little or no change in spread over the same time period.

## Royal Academy Dates

```{r ra}

# Plot top N days against RA exhibition dates

# Join a table with the top N days together
ra_overlap <- peak_n %>%
  left_join(peak_sum, by = c("year", "price_factor")) %>%
  left_join(peak_avg, by = c("year", "price_factor")) %>%
  gather(type, yday, count_day, sum_day, avg_day) %>%
  distinct() %>%
  # Join the Royal Academy exhibition dates, and calculate which ones take place
  # during the exhibition
  inner_join(ra_dates %>% select(year = exhib_year, exhib_start_day, exhib_end_day), by = "year") %>%
  mutate(during_exhib = yday >= exhib_start_day & yday <= exhib_end_day) %>%
  # Keep only selected quintiles, and re-label the type factor
  filter(price_factor == 5) %>%
  mutate(
    type = factor(
      type,
      levels = c("avg_day", "count_day", "sum_day"),
      labels = c( "Highest average price", "Highest number of sales", "Higest total revenue"))) %>% 
  # Calculate the ratio of top N days that take place during the RA exhibition
  group_by(year, price_factor, type) %>% 
  mutate(n = mean(during_exhib)) %>% 
  ungroup()
  
ra_plot <- ggplot(ra_overlap, aes(x = year, y = yday)) +
  geom_point(size = 2, alpha = 0.5) +
  geom_ribbon(aes(ymin = exhib_start_day, ymax = exhib_end_day, na.rm = TRUE), alpha = 0.5) +
  geom_rug(aes(color = n), size = 2, sides = "b") +
  scale_color_gradient(low = "white", high = "red") +
  facet_wrap(~ type, nrow = 1) +
  theme_bw() +
  theme(
    legend.position = "bottom",
    axis.text.x = element_text(angle = 45, hjust = 1)
  ) +
  labs(
    x = "Year",
    y = "Day of the year",
    color = "Ratio of top auction days
    during RA exhibition",
    alpha = "Royal Exhibition open"
  ) +
  ylim(1, 365)
dualplot(ra_plot, "ra_plot")
```

We can also plot the parliament session dates for the same period. Around
1780-1800, the top sales days were generally spread from the start of parliament
until the end; however these became increasingly clustered towards the close of
parliament. Unsurprisingly, the Parliament meeting dates set the outer bounds of
the auction season. However within those bounds, more interesting activity was
afoot.

```{r}
parliament_overlap <- peak_n %>%
  left_join(peak_sum, by = c("year", "price_factor")) %>%
  left_join(peak_avg, by = c("year", "price_factor")) %>%
  gather(type, yday, count_day, sum_day, avg_day) %>%
  distinct() %>%
  # Join the parliament dates, and calculate which ones take place
  # during the exhibition
  inner_join(parliament_dates %>% select(year = par_start_year, par_start_day, par_end_day), by = "year") %>%
  # Keep only selected quintiles, and re-label the type factor
  filter(price_factor == 5) %>%
  mutate(
    type = factor(
      type,
      levels = c("avg_day", "count_day", "sum_day"),
      labels = c( "Highest average price", "Highest number of sales", "Higest total revenue")))

par_plot <- ggplot(parliament_overlap, aes(x = year, y = yday)) +
  geom_point(size = 2, alpha = 0.5) +
  geom_point(aes(y = par_end_day, na.rm = TRUE), alpha = 0.5, color = "red") +
  geom_point(aes(y = par_start_day, na.rm = TRUE), alpha = 0.5, color = "blue") +
  facet_wrap(~ type, nrow = 1) +
  theme_bw() +
  theme(
    legend.position = "bottom",
    axis.text.x = element_text(angle = 45, hjust = 1)
  ) +
  labs(
    x = "Year",
    y = "Day of the year"
  ) +
  ylim(1, 365)

dualplot(par_plot, "par_plot")
```
